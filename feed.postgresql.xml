<?xml version="1.0" encoding="UTF-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
 <channel>
  <title> - postgresql</title>
  <description>Posts tagged as 'postgresql'</description>
  <atom:link href="http://hunleyd.github.io/feed.postgresql.xml" rel="self" type="application/rss+xml" />
  <link>http://hunleyd.github.io/tag/postgresql/</link>
  <updated>2016-11-02T10:32:04-04:00</updated>
  <author>
   <name></name>
   <email></email>
  </author>

  
   <item>
    <title>Announcing pgCMH</title>
    <description>&lt;p&gt;&lt;img src=&quot;/images/pgCMH.png&quot; border=0 height=200 width=200 align=right&gt;I&amp;#39;ve been kicking around the idea of founding a Columbus-based PostgreSQL User Group for a while now. I even went so far as to float the idea to people at &lt;a href=&quot;http://www.ohiolinux.org&quot;&gt;OLF&lt;/a&gt; in &amp;#39;14. After much hemming and hawing (and no one else stepping up in the interim), I&amp;#39;ve finally gone and done it.&lt;/p&gt;

&lt;p&gt;pgCMH is the name of my newly formed group, and we&amp;#39;re good to go. We&amp;#39;ve got our own Twitter (&lt;a href=&quot;http://www.twitter.com/pgCMH&quot;&gt;@pgCMH&lt;/a&gt;):&lt;/p&gt;

&lt;div class='jekyll-twitter-plugin'&gt;&lt;blockquote class=&quot;twitter-tweet&quot;&gt;&lt;p lang=&quot;en&quot; dir=&quot;ltr&quot;&gt;&lt;a href=&quot;https://twitter.com/hashtag/PostgreSQL?src=hash&quot;&gt;#PostgreSQL&lt;/a&gt; 9.6.1, 9.5.5, 9.4.10, 9.3.15, 9.2.19 and 9.1.24 Released! &lt;a href=&quot;https://t.co/RH27To33gh&quot;&gt;https://t.co/RH27To33gh&lt;/a&gt;&lt;/p&gt;&amp;mdash; pgCMH (@pgCMH) &lt;a href=&quot;https://twitter.com/pgCMH/status/791654418731065344&quot;&gt;October 27, 2016&lt;/a&gt;&lt;/blockquote&gt;
&lt;script async src=&quot;//platform.twitter.com/widgets.js&quot; charset=&quot;utf-8&quot;&gt;&lt;/script&gt;&lt;/div&gt;

&lt;p&gt;as well as our own &lt;a href=&quot;http://www.meetup.com/postgresCMH&quot;&gt;MeetUp&lt;/a&gt; page. We&amp;#39;ve got a sponsor providing food, and another providing the meeting location. Our first meeting will be in Jan, thanks to all the scheduling conflicts the upcoming holidays create.&lt;/p&gt;

&lt;p&gt;Watch this space for updates, follow our Twitter, and join the mailing list on MeetUp. I&amp;#39;d love to get your participation and input. Let&amp;#39;s make this group as wildly successful as we can!&lt;/p&gt;
</description>
    <link>http://hunleyd.github.io/Announcing-pgCMH/ </link>
    <pubDate>2016-10-31T07:35:22-04:00</pubDate>
    <guid isPermaLink="true">http://hunleyd.github.io/Announcing-pgCMH/</guid>
   </item>
  
   <item>
    <title>Incremental pgBadger</title>
    <description>&lt;p&gt;&lt;img src=&quot;https://dalibo.github.io/pgbadger/logo_pgbadger.png&quot; border=0 align=left&gt; You&amp;#39;re probably already running &lt;a href=&quot;https://dalibo.github.io/pgbadger/index.html&quot;&gt;pgBadger&lt;/a&gt; to monitor your PostgreSQL logs. However, you&amp;#39;re probably &lt;em&gt;not&lt;/em&gt; running it incrementally throughout the day. Most likely, you&amp;#39;ve setup a &lt;code&gt;cron.daily&lt;/code&gt; job that runs pgBadger against yesterday&amp;#39;s log(s). And that&amp;#39;s great. Except when you get the dreaded &amp;quot;what just happened on the db?&amp;quot; email. Are you going to wait until tonight&amp;#39;s normal run of pgBadger to see what happened? Are you going to run a &amp;#39;one off&amp;#39; pgBadger against today&amp;#39;s logfile and wait for it to process the &lt;em&gt;entire&lt;/em&gt; log? Or are you going to copy the log off somewhere, edit it to cut it down, and &lt;em&gt;then&lt;/em&gt; run pgBadger against this cut-down version (hoping you left enough in the log to see proper trending)?&lt;/p&gt;

&lt;p&gt;No, most likely you&amp;#39;re going to look at your actual monitoring tool that does real-time monitoring of your db and try to figure things out from there. You &lt;em&gt;are&lt;/em&gt; running some kind of db monitoring tool, right?&lt;/p&gt;

&lt;p&gt;However, let&amp;#39;s say that for, uh, reasons, you only have pgBadger at your disposal &lt;em&gt;right this instant&lt;/em&gt;. Well, if you were making use of pgBadger&amp;#39;s &lt;em&gt;incremental mode&lt;/em&gt; you could simply fire off the next scheduled run and it would only process those log entries that were new since the last run. So, for example, if you had a &lt;code&gt;cron.hourly&lt;/code&gt; run of pgBadger it would only process the last hour&amp;#39;s worth of entries to update today&amp;#39;s report. No waiting to process multiple hours of info that you don&amp;#39;t need, no editing of the logfile to remove things outside the window you care about, just run it and done.&lt;/p&gt;

&lt;p&gt;Sounds nice, right? So let&amp;#39;s set this up shall we? I&amp;#39;m assuming you&amp;#39;ve already setup &lt;code&gt;postgresql.conf&lt;/code&gt; appropriately, but if you haven&amp;#39;t please go that first. The pgBadger website has good documentation on how to do so. According to the docs:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-apache&quot; data-lang=&quot;apache&quot;&gt;-I | --incremental     : use incremental mode, reports will be generated by days in a separate directory, --outdir must be set.
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;is how we turn on incremental mode. You&amp;#39;ll note that we also need to specify an output dir:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-apache&quot; data-lang=&quot;apache&quot;&gt;-O | --outdir path     : directory where out file must be saved
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;I usually stick the pgBadger output into the &lt;code&gt;pg_log&lt;/code&gt; directory. In my mind, having the logs and the report on the logs next to each makes sense, but feel free to stick yours wherever.&lt;/p&gt;

&lt;p&gt;Finally, we probably don&amp;#39;t need pgBadger reports that are too old, and the docs say we can cull the cruft automatically:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-apache&quot; data-lang=&quot;apache&quot;&gt;-R | --retention N     : number of week to keep in incremental mode. Default to 0, disabled. Used to set the number of weel to keep in output directory. Older weeks and days directory are automatically removed.
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;(Ignore the typo, it&amp;#39;s that way in the code)&lt;/p&gt;

&lt;p&gt;On my servers, I have PostgreSQL setup to log into a different file for each day of the week, with automatic rotation and truncation:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;log_filename = &amp;#39;postgresql-%a.log&amp;#39;
log_truncate_on_rotation = on
log_rotation_age = 1d
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;so my &lt;code&gt;cron.hourly&lt;/code&gt; pgBadger looks like:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;pgbadger \
    -I \
    -O $PGDATA/pg_log \
    -R 12 \
    -q \
    $PGDATA/pg_log/postgresql-$(date --date yesterday +%a) \
    $PGDATA/pg_log/postgresql-$(date +%a)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;which as you can see always feeds both yesterday&amp;#39;s and today&amp;#39;s log into pgBadger (since the cron runs at 2300 and then again at 0000, we need yesterday&amp;#39;s log to catch that last hour). Since we&amp;#39;re running in incremental mode, it knows &lt;em&gt;at every run&lt;/em&gt; where it left off in the files the last time and does a &lt;code&gt;seek&lt;/code&gt; to skip over that data. This cuts the run time down &lt;em&gt;significantly&lt;/em&gt; even with the PostgreSQL logging &lt;em&gt;cranked up&lt;/em&gt;. You can see it here:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;...
DEBUG: Starting reading file postgresql-Wed.log...
DEBUG: Start parsing at offset 412677131 of file postgresql-Wed.log to 433543395
[======================&amp;gt;  ] Parsed 413815537 bytes of 433543395 (95.45%), queries
...
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;As you can see, it jumps right in at 95% of the file and only processes the newest 5%. In fact, this takes a mere 20 seconds:&lt;/p&gt;
&lt;figure class=&quot;highlight&quot;&gt;&lt;pre&gt;&lt;code class=&quot;language-text&quot; data-lang=&quot;text&quot;&gt;statistics gathering took:20 wallclock secs (19.44 usr +  0.17 sys = 19.61 CPU)
&lt;/code&gt;&lt;/pre&gt;&lt;/figure&gt;
&lt;p&gt;on my overloaded Macbook!&lt;/p&gt;

&lt;p&gt;So there you have it. Not counting the time it takes you to &lt;code&gt;ssh&lt;/code&gt; to your server, it would have taken all of &lt;em&gt;20 seconds&lt;/em&gt; to have an updated report of what just happened on your database!&lt;/p&gt;

&lt;p&gt;Keep in mind, this is also with a &lt;em&gt;single thread&lt;/em&gt;. pgBadger has the ability to run multi-threaded. See the &lt;code&gt;--help&lt;/code&gt; for details.&lt;/p&gt;

&lt;p&gt;Enjoy!&lt;/p&gt;
</description>
    <link>http://hunleyd.github.io/Incremental-pgBadger/ </link>
    <pubDate>2016-10-26T10:46:09-04:00</pubDate>
    <guid isPermaLink="true">http://hunleyd.github.io/Incremental-pgBadger/</guid>
   </item>
  
   <item>
    <title>I'm syndicated</title>
    <description>&lt;p&gt;Someone at work thought it would be a good idea to give me access to the corporate blog so that I might &lt;a href=&quot;http://www.openscg.com/category/postgresql-blogs/doug-postgresql/&quot;&gt;post&lt;/a&gt; PostgreSQL-related things there and have them syndicted to &lt;a href=&quot;http://planet.postgresql.org/&quot;&gt;Planet PostgreSQL&lt;/a&gt;. So my PostgreSQL ramblings will show up there now instead of here. This should be fun!&lt;/p&gt;
</description>
    <link>http://hunleyd.github.io/Im-Syndicated/ </link>
    <pubDate>2016-10-08T11:19:57-04:00</pubDate>
    <guid isPermaLink="true">http://hunleyd.github.io/Im-Syndicated/</guid>
   </item>
  
   <item>
    <title>Where Not To Put Your Tablespaces</title>
    <description>&lt;p&gt;From the PostgreSQL &lt;a href=&quot;https://www.postgresql.org/docs/current/static/manage-ag-tablespaces.html&quot;&gt;docs&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Tablespaces in PostgreSQL allow database administrators to define locations in the file system where the files representing database objects can be stored. Once created, a tablespace can be referred to by name when creating database objects.&lt;/p&gt;

&lt;p&gt;By using tablespaces, an administrator can control the disk layout of a PostgreSQL installation. This is useful in at least two ways. First, if the partition or volume on which the cluster was initialized runs out of space and cannot be extended, a tablespace can be created on a different partition and used until the system can be reconfigured.&lt;/p&gt;

&lt;p&gt;Second, tablespaces allow an administrator to use knowledge of the usage pattern of database objects to optimize performance. For example, an index which is very heavily used can be placed on a very fast, highly available disk, such as an expensive solid state device. At the same time a table storing archived data which is rarely used or not performance critical could be stored on a less expensive, slower disk system.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;As you can see, while not as powerful as tablespaces in, say, Oracle, they do still have their uses in PostgreSQL. You can use them to make use of different filesystems, or different mount options, or different disk types and, in doing so, intelligently apply performance characteristics to subsets of your data. For example, you could put your highest volume tables in a tablespace that is mounted from SSDs while the rest of your db is mounted from spinning rust.&lt;/p&gt;

&lt;p&gt;Sounds decent, right? Now you before you go off and be &amp;quot;clever&amp;quot; and create an SSD-backed mountpoint for your new tablespace, understand that there are places you &lt;em&gt;should not&lt;/em&gt; create the tablespace. You shouldn&amp;#39;t create tablespaces on any kind of ephemeral storage, for example on a &lt;code&gt;tmpfs&lt;/code&gt; or a &lt;code&gt;ramfs&lt;/code&gt; or similar. &lt;em&gt;You also should not create your new tablespaces under $PGDATA&lt;/em&gt;. Yes, I&amp;#39;m aware there is &lt;code&gt;$PGDATA/pg_tblspc&lt;/code&gt; but that directory is &lt;em&gt;not for you&lt;/em&gt;. The system will auto-populate that directory with pointers to the real location of your tablespaces!&lt;/p&gt;

&lt;p&gt;So what happens when you create a tablespace inside $PGDATA? Let&amp;#39;s find out. First, we&amp;#39;ll create the directory for the tablespace:&lt;/p&gt;

&lt;p&gt;&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
doug.hunley ~ $ mkdir $PGDATA/tablespaces
doug.hunley ~ $ cd $PGDATA/tablespaces
doug.hunley ~/pgdata/tablespaces $ pwd
/Users/doug.hunley/pgdata/tablespaces
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/abe0d33a02ae2d5ee515f7f0261d000c.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;And we see that nothing bad has happened yet. So, let&amp;#39;s pop over into &lt;code&gt;psql&lt;/code&gt; and actually create the tablespace:&lt;/p&gt;

&lt;p&gt;&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;sql
(doug.hunley@[local]:5432/doug.hunley) # CREATE TABLESPACE ts1 LOCATION &amp;amp;#39;/Users/doug.hunley/pgdata/tablespaces&amp;amp;#39;;
WARNING:  42P17: tablespace location should not be inside the data directory
LOCATION:  CreateTableSpace, tablespace.c:295
CREATE TABLESPACE
Time: 7.797 ms
(doug.hunley@[local]:5432/doug.hunley) #
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/dba03610d0181abe363378ccaedafb98.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;We get a warning (not an error, for some reason) but it works and all appears fine. Now you can spend minutes/days/months/years using your new tablespace and never notice that you&amp;#39;ve got a problem. So where does the problem come in? &lt;/p&gt;

&lt;p&gt;Let&amp;#39;s try to make a backup of our cluster:&lt;/p&gt;

&lt;p&gt;&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
doug.hunley ~ $ pg_basebackup -D pgdata2 -Fp -R -Xs -c fast -l &amp;amp;#39;clone for slave&amp;amp;#39; -P -v
transaction log start point: 2/17000028 on timeline 1
pg_basebackup: directory &amp;amp;quot;/Users/doug.hunley/pgdata/tablespaces&amp;amp;quot; exists but is not empty
doug.hunley ~ $
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/d55de865904c475ce0099eb03732251b.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;There it is.&lt;/p&gt;

&lt;p&gt;When creating the backup, it tries to ensure the tablespace location is the same, but then it won&amp;#39;t write to a non-empty directory. My example is two different $PGDATA locations on the same box, but the issue is the same when using different machines because &lt;code&gt;pg_basebackup&lt;/code&gt; backs up &lt;em&gt;everything&lt;/em&gt; in $PGDATA which means your tablespace directory gets cloned before it gets to the actual cloning of the data in the tablespace so you end up with &amp;quot;stuff&amp;quot; in the dir, making it non-empty. Which gives you the same error and output.&lt;/p&gt;

&lt;p&gt;OK, so it breaks backups. I can work around that by using another backup method. What else?&lt;/p&gt;

&lt;p&gt;How about using &lt;code&gt;pg_upgrade&lt;/code&gt; to do an upgrade? No matter if you run in &lt;code&gt;link&lt;/code&gt; mode or not, &lt;code&gt;pg_upgrade&lt;/code&gt; &lt;em&gt;will not move&lt;/em&gt; your tablespace location. So you may have &lt;code&gt;~/pgdata95&lt;/code&gt; and &lt;code&gt;~/pgdata96&lt;/code&gt; after the upgrade, but your tablespaces &lt;em&gt;are still in&lt;/em&gt; &lt;code&gt;~/pgdata95/tablespaces&lt;/code&gt;. So, as per the &lt;a href=&quot;https://www.postgresql.org/docs/current/static/pgupgrade.html&quot;&gt;docs&lt;/a&gt;:&lt;/p&gt;

&lt;blockquote&gt;
&lt;p&gt;Once you are satisfied with the upgrade, you can delete the old cluster&amp;#39;s data directories by running the script mentioned when pg_upgrade completes.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;And &lt;em&gt;boom&lt;/em&gt; you&amp;#39;ve just deleted your tablespaces off disk. Congratulations!&lt;/p&gt;

&lt;p&gt;So there you have it. Two very good reasons to not create tablespaces inside $PGDATA. Please, don&amp;#39;t do this. Everyone who admins that cluster going forward will thank you.&lt;/p&gt;
</description>
    <link>http://hunleyd.github.io/Where-Not-To-Put-Your-Tablespaces/ </link>
    <pubDate>2016-08-24T07:55:12-04:00</pubDate>
    <guid isPermaLink="true">http://hunleyd.github.io/Where-Not-To-Put-Your-Tablespaces/</guid>
   </item>
  
   <item>
    <title>Happy 20th Birthday, PostgreSQL</title>
    <description>&lt;p&gt;&lt;img src=&quot;/images/pgsql_20th.png&quot; width=200 height=200 border=0 align=left style=&quot;PADDING-RIGHT: 5px&quot;&gt;Just a quick shout out to PostgreSQL, the world&amp;#39;s most advanced open source database, as it celebrates it&amp;#39;s 20&lt;sup&gt;th&lt;/sup&gt; year in existence. Happy birthday, y&amp;#39;all!&lt;/p&gt;
</description>
    <link>http://hunleyd.github.io/Happy-20th-PostgreSQL/ </link>
    <pubDate>2016-05-12T06:11:31-04:00</pubDate>
    <guid isPermaLink="true">http://hunleyd.github.io/Happy-20th-PostgreSQL/</guid>
   </item>
  
   <item>
    <title>PostgreSQL Partitioning Quick Tip</title>
    <description>&lt;p&gt;&lt;img src=&quot;http://www.habitsofmind.org/sites/default/files/helpful-tips-image-web-design-sydney.jpg&quot; align=right border=0&gt;Partitioning in PostgreSQL can be a little daunting at times. In fact, you should probably just use &lt;a href=&quot;https://github.com/keithf4/pg_partman&quot;&gt;pg_partman&lt;/a&gt; and be done with it. However, if you&amp;#39;re trying to learn, can&amp;#39;t use &lt;code&gt;pg_partman&lt;/code&gt;, or are a masochist you&amp;#39;ll probably be following the &lt;a href=&quot;http://www.postgresql.org/docs/current/static/ddl-partitioning.html&quot;&gt;docs&lt;/a&gt; and thinking &amp;#39;seriously? i have to create indexes on each child? why don&amp;#39;t they copy the indexes of the parent? why isn&amp;#39;t this easier?&amp;#39;. Here&amp;#39;s a little tip to make things slightly easier:&lt;/p&gt;

&lt;p&gt;Instead of creating your child tables like the doc says:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;sql
CREATE TABLE child1 (
  CHECK (blah blah)
) INHERITS (parent);
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/0b1f8fa43534f53046eed4e63dc54e14.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Create your child tables thusly:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;sql
CREATE TABLE child1 (
  LIKE parent INCLUDING ALL,
  CHECK (blah blah)
) INHERITS (parent);
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/603c5f6961134422651e2e13b1c6398e.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;and PostgeSQL &lt;em&gt;will&lt;/em&gt; copy all your indexes, primary keys, etc from the parent to the child. Which is what you wanted, right?&lt;/p&gt;

&lt;p&gt;Enjoy.&lt;/p&gt;
</description>
    <link>http://hunleyd.github.io/PostgresQL-Partitioning-Quick-Tip/ </link>
    <pubDate>2016-04-21T05:25:32-04:00</pubDate>
    <guid isPermaLink="true">http://hunleyd.github.io/PostgresQL-Partitioning-Quick-Tip/</guid>
   </item>
  
   <item>
    <title>Logical Replication with Skytools3</title>
    <description>&lt;p&gt;&lt;img src=&quot;https://cdn2.iconfinder.com/data/icons/color-svg-cloud-icons/512/cloud_refresh-512.png&quot; width=225 height=225 border=0 align=left&gt; UPDATE: My coworker Richard liked this write up, and Skytools, so much he threw together a demo script. You can get it &lt;a href=&quot;https://github.com/richyen/toolbox/blob/master/pg/londiste/londiste_demo.sh&quot;&gt;here&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;I recently had to do a &lt;em&gt;near-zero downtime&lt;/em&gt; upgrade from PostgreSQL 8.4.x to PostgreSQL 9.4.x for a custmer. I couldn&amp;#39;t use streaming replication because of the change in major version (and because it&amp;#39;s simply not present in 8.x), so that left me looking at &lt;em&gt;logical replication&lt;/em&gt; options. Usually, everyone else would be thinking Slony right here. I&amp;#39;ve only messed with Slony a few times, but each time was a pita, and the whole thing just seemed overly complicated to me. So I decided to give Londiste a look.&lt;/p&gt;

&lt;p&gt;Londiste is part of the Skytools suite, originally developed by Skype back when they were a &amp;#39;no central node&amp;#39; setup. As such, the thing was literally born to be &amp;quot;master-master&amp;quot; and assumes nodes come and go at will, so it&amp;#39;s got all the tools to handle bringing nodes up/down, marking them active/inactive, catching them up, etc. It&amp;#39;s written in Python, and uses plain text ini files for configuration.&lt;/p&gt;

&lt;p&gt;There&amp;#39;s really only two hurdles that I found with using Londiste. First is that if you can&amp;#39;t get the rpms from the &lt;a href=&quot;http://yum.postgresql.org&quot;&gt;PGDG Yum Repo&lt;/a&gt; you&amp;#39;re looking at compiling from Git. And second, the online documentation for it is hard to find, hard to follow, and practically no one has used it so you can&amp;#39;t ask RandomPostgresPerson for help.&lt;/p&gt;

&lt;p&gt;Which is exactly why I&amp;#39;m writing this blog post. Here&amp;#39;s what I needed to get me through the migration in question. I hope it helps you, should you consider using Londiste for your own replication needs. To whit:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;As with other logical replication tools, you must ensure that all the tables to be replicated have a valid primary key. So before you even get started, determine which tables are missing them and then pass that list to your junior DBA and have them create pkeys while you continue on:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;sql
SELECT
n.nspname as schema,
c.relname as table
FROM
pg_class c
JOIN
pg_namespace n
ON
n.oid = c.relnamespace
WHERE
c.relkind = &amp;amp;#39;r&amp;amp;#39;
AND NOT EXISTS (
SELECT
    1
FROM
    pg_constraint con
WHERE
    con.conrelid = c.oid
AND
    con.contype = &amp;amp;#39;p&amp;amp;#39;
)
AND n.nspname &amp;amp;lt;&amp;amp;gt; ALL (
ARRAY [
    &amp;amp;#39;pg_catalog&amp;amp;#39;,
    &amp;amp;#39;sys&amp;amp;#39;,
    &amp;amp;#39;dbo&amp;amp;#39;,
    &amp;amp;#39;information_schema&amp;amp;#39;
]
);
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/94d1096767e154486dbfe8dd47f48275.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;On the PostgreSQL 9.4.x server that will be receiving the replicated data, we need to ensure that all roles are pre-created. We want all ownerships and grants to be identical when we&amp;#39;re done, right? You can use &lt;code&gt;pg_dumpall -g&lt;/code&gt; on the PostgreSQL 8.4.x to get a listing of roles.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Again, like Slony, we should pre-build the schema on the PostgreSQL 9.4.x server. I &lt;em&gt;think&lt;/em&gt; you can actually get Londiste to do this for you as part of the replication, but I couldn&amp;#39;t find anything online for sure, and I didn&amp;#39;t have time to add more experimentation here (we&amp;#39;re on the customer&amp;#39;s dime here, remember). So, use &lt;code&gt;pg_dump&lt;/code&gt; over the network and pipe it to &lt;code&gt;pg_restore&lt;/code&gt; to transfer the schema thusly:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
pg_dump \
-Fc \
-C \
-S \
-h IPofOldServer \
-U postgres \
myapp | \
pg_restore \
-d template1 \
-v \
-C \
-e \
-s
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/f0fcb06526f3b3f50dd0b57a091403b8.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Install Skytools on the PostgreSQL 9.4.x server using the PGDG repo:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
yum -y install \
skytools-94 \
skytools-94-modules
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/00e6122b49c7f068c46e680f09ed396f.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Install Skytools from source on the PostgreSQL 8.4.x server:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
yum -y install \
python-devel \
asciidoc \
xmlto \
postgresql-devel
git clone git://github.com/markokr/skytools.git
cd skytools
git submodule init
git submodule update
./autogen.sh
./configure
make
make install
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/555804964c2e2564b08fff01c0d5a53a.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Restart the PostgreSQL 8.4.x cluster to load the new libs and modules&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now we configure the Londiste ticker. Note, we have &lt;em&gt;trust&lt;/em&gt; setup for the postgres user in &lt;code&gt;pg_hba.conf&lt;/code&gt; so there is no password= in the connection strings. Adjust to meet your setup:
&lt;noscript&gt;&lt;pre&gt;```bash
mkdir -pv ~postgres/londiste-config/{log,pid}
cd ~postgres/londiste-config
cat &amp;lt;&amp;lt; EOF &amp;gt; ticker.ini
[pgqd]
base&lt;em&gt;connstr = user=postgres host=IPofOldServer
database&lt;/em&gt;list = myapp
logfile = log/ticker.log
pidfile = pid/ticker.pid
EOF&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/d65e5dfd27365b086dcddb118d586308.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Start up the ticker, to provide the replication &amp;quot;heartbeat&amp;quot; by running &lt;code&gt;pgqd -d ticker.ini&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Check the &lt;code&gt;ticker.log&lt;/code&gt; to ensure there are no warnings or errors! You can stop the ticker with &lt;code&gt;pgqd -s ticker.ini&lt;/code&gt; while you fix things.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now, we tell Londiste about the master node (same note applies about the lack of password in the connection string):
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
cd ~postgres/londiste-config
cat &amp;amp;lt;&amp;amp;lt; EOF &amp;amp;gt; master.ini
[londiste3]
db = user=postgres host=IPofOldServer dbname=myapp
queue_name = myappq
loop_delay = 0.5
logfile = log/master.log
pidfile = pid/master.pid
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/2a9317184569c8fabd26945595c480f9.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;We have to actually create the master node as the root node by doing:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
londiste3 \
master.ini \
create-root \
master &amp;amp;#39;user=postgres host=IPofOldServer dbname=myapp&amp;amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/fcfb0ff9b3cbb2c724ea8da36723fde1.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Check the master.log to see if you have a line like &lt;code&gt;INFO Node &amp;quot;master&amp;quot; initialized for queue &amp;quot;myappq&amp;quot; with type &amp;quot;root&amp;quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Now, spin up the master&amp;#39;s replication worker process by running &lt;code&gt;londiste3 -d master.ini worker&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Next, we configure our slave node (same note applies about the lack of password in the connection string):
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
cd ~postgres/londiste-config
cat &amp;amp;lt;&amp;amp;lt; EOF &amp;amp;gt; slave.ini
[londiste3]
db = user=postgres host=127.0.0.1 dbname=myapp
queue_name = myappq
loop_delay = 0.5
logfile = log/slave.log
pidfile = pid/slave.pid
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/94ac2474673bd3dd9fe0e1d77a12c791.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Like the master, we have to create the slave node. I created it as a &lt;code&gt;leaf&lt;/code&gt; but I could have created it as a &lt;code&gt;branch&lt;/code&gt; if we we&amp;#39;re going to cascade replication:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
londiste3 \
slave.ini \
create-leaf slave &amp;amp;#39;user=postgres host=127.0.0.1 dbname=myapp&amp;amp;#39; \
--provider=&amp;amp;#39;user=postgres host=IPofOldServer dbname=myapp&amp;amp;#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/bdcd1644a185863f823749d4502e2fa8.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Check the slave.log to see if you have the line &lt;code&gt;INFO Node &amp;quot;slave&amp;quot; initialized for queue &amp;quot;myappq&amp;quot; with type &amp;quot;branch&amp;quot;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Spin up the slave&amp;#39;s replication worker process by running &lt;code&gt;londiste3 -d slave.ini worker&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Tell the master node that we want to replicate all the tables in the db (&lt;code&gt;londiste3 master.ini add-table --all&lt;/code&gt;) as well as all the sequences (&lt;code&gt;londiste3 master.ini add-seq --all&lt;/code&gt;). Note that this only adds the tables that currently exist. If you add new tables to the master db, you need to &lt;code&gt;londiste3 master.ini add-table tablename&lt;/code&gt; to add them to replication. Ditto for new sequences.&lt;/p&gt;&lt;/li&gt;
&lt;li&gt;&lt;p&gt;For the slave node, also replicate all the tables (&lt;code&gt;londiste3 slave.ini add-table --all&lt;/code&gt;) and all the sequences (&lt;code&gt;londiste3 slave.ini add-seq --all&lt;/code&gt;). Note that this only adds the tables that currently exist. If you add new tables to the master db, you need to &lt;code&gt;londiste3 slave.ini add-table tablename&lt;/code&gt; to add them to replication. Ditto for new sequences.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;At this point, replication is actually up and running. Any changes occurring on the master node are being replicated to the slave node. That&amp;#39;s all you need to do.&lt;/p&gt;

&lt;p&gt;But what about the data that was already in the master db? You don&amp;#39;t need to do anything. It&amp;#39;s already replicating. You can forcibly tell Londiste to &amp;#39;catch things up&amp;#39; by doing &lt;code&gt;londiste3 slave.ini resync --all&lt;/code&gt; if you like though.&lt;/p&gt;

&lt;p&gt;If you want to check on the replication at any point, simply issue &lt;code&gt;londiste3 slave.ini status&lt;/code&gt; or to be more pedantic &lt;code&gt;londiste3 slave.ini compare&lt;/code&gt; which will examine row counts and md5sums between master and slave.&lt;/p&gt;

&lt;p&gt;Enjoy your new cross-version logical replication!&lt;/p&gt;
</description>
    <link>http://hunleyd.github.io/Logical-Replication-With-Skytool3/ </link>
    <pubDate>2016-04-19T09:55:11-04:00</pubDate>
    <guid isPermaLink="true">http://hunleyd.github.io/Logical-Replication-With-Skytool3/</guid>
   </item>
  
   <item>
    <title>PostgreSQL Streaming Replication in 10 Minutes</title>
    <description>&lt;p&gt;&lt;img src=&quot;https://unitedlayer.com/sites/default/files/dr-icons-01.png&quot; border=0 align=right&gt;While there&amp;#39;s absolutely nothing new in this blog post that isn&amp;#39;t covered by the wonderful &lt;a href=&quot;http://www.postgresql.org/docs/current/static/index.html&quot;&gt;docs&lt;/a&gt; I&amp;#39;ve been asked multiple times now by customers if we had some kind of &amp;#39;crib notes&amp;#39; format for how to get replication up and running. And since I just had to set this up and document it for a customer, I figured I might as well post it so that I can simply point people to it in the future. So here we are.&lt;/p&gt;

&lt;p&gt;Now, let&amp;#39;s get started. I assume you already have two PostgreSQL servers up with the binaries installed. For simplicity&amp;#39;s sake, we will call these machines &amp;#39;master&amp;#39; and &amp;#39;standby&amp;#39;. Note too that I&amp;#39;m using &lt;code&gt;replication slots&lt;/code&gt; which needs PostgreSQL 9.4.0 or later; if you&amp;#39;re using something earlier, simply ignore the slot stuff.&lt;/p&gt;

&lt;p&gt;Let&amp;#39;s get started!&lt;/p&gt;

&lt;p&gt;On the master, do the following:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
cat &amp;amp;lt;&amp;amp;lt; EOF &amp;amp;gt;&amp;amp;gt; postgresql.conf
    wal_level = hot_standby
    full_page_writes = on
    wal_log_hints = on
    max_wal_senders = 6
    max_replication_slots = 6
    hot_standby = on
    hot_standby_feedback = on
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/78f5bca50fb14e5a6525a5f63bb5bf47.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;On the master, add the external IP addresses of the servers to &lt;code&gt;pg_hba.conf&lt;/code&gt;:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
cat &amp;amp;lt;&amp;amp;lt; EOF &amp;amp;gt;&amp;amp;gt; pg_hba.conf
    host replication repl_user IP_of_master/32 md5
    host replication repl_user IP_of_standby/32 md5
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/8af26b72f5a79632494d3203547d9478.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Restart PostgreSQL on the master for the changes to take affect&lt;/p&gt;

&lt;p&gt;On the master, create the replication user:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
psql \
  -d postgres \
  -U postgres \
  -c &amp;amp;quot;CREATE ROLE repl_user LOGIN REPLICATION ENCRYPTED PASSWORD &amp;amp;#39;secretpasswordhere&amp;amp;#39;;&amp;amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/a279de475a73e8ee490b1c7af7859ba4.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;On the master, create the replication slot for the standby:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
psql \
  -d postgres \
  -U postgres \
  -c &amp;amp;quot;SELECT * FROM pg_create_physical_replication_slot(&amp;amp;#39;standby1&amp;amp;#39;);&amp;amp;quot;
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/2fb5070785137383fe42eec0225d8c0e.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;On the standby, wipe the existing cluster:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
cd /var/lib/pgsql/9.4/data
pg_ctl -D $PWD -mf stop
cd ..
rm -rfv data
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/2adfa47297b9d0006ba172d967e1a575.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;On the standby, use the &lt;code&gt;pg_basebackup&lt;/code&gt; command to clone the master (enter the &lt;code&gt;repl_user&lt;/code&gt;&amp;#39;s password from above when prompted):
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
pg_basebackup \
  -D data \
  -Fp \
  -R \
  -Xs \
  -c fast \
  -l &amp;amp;#39;initial clone&amp;amp;#39; \
  -P \
  -v \
  -h IP_of_master \
  -U repl_user
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/3e37d6f4ede70675270b92d7660cd1d0.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;On the standby, tweak the &lt;code&gt;recovery.conf&lt;/code&gt; that was created for you and add the replication slot name:
&lt;noscript&gt;&lt;pre&gt;&lt;code&gt;bash
cd data
cat &amp;amp;lt;&amp;amp;lt; EOF &amp;amp;gt;&amp;amp;gt; recovery.conf
primary_slot_name = &amp;amp;#39;standby1&amp;amp;#39;
EOF
&lt;/code&gt;&lt;/pre&gt;&lt;/noscript&gt;&lt;script src=&quot;https://gist.github.com/hunleyd/e914002c0c78c3a1c03515c60e2b5aaa.js&quot;&gt; &lt;/script&gt;&lt;/p&gt;

&lt;p&gt;Start the standby up&lt;/p&gt;

&lt;p&gt;And that&amp;#39;s it. You should be all done. Easy, right?&lt;/p&gt;
</description>
    <link>http://hunleyd.github.io/PostgreSQL-Streaming-Replication-In-10-Minutes/ </link>
    <pubDate>2016-04-18T10:47:10-04:00</pubDate>
    <guid isPermaLink="true">http://hunleyd.github.io/PostgreSQL-Streaming-Replication-In-10-Minutes/</guid>
   </item>
  
 </channel>
</rss>
